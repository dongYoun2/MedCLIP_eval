{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0e1e503",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f23f609",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from medclip import MedCLIPModel, MedCLIPProcessor, PromptClassifier\n",
    "from medclip.prompts import generate_tb_class_prompts\n",
    "from medclip.dataset import ZeroShotImageDataset, ZeroShotImageCollator\n",
    "from medclip.evaluator import Evaluator\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "696d4d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 700 TB images\n",
      "Found 3500 Normal images\n",
      "\n",
      "Sampled 700 TB images\n",
      "Sampled 700 Normal images\n",
      "\n",
      "Saved metadata to: local_data/tb-test-meta.csv\n"
     ]
    }
   ],
   "source": [
    "tb_dir = Path('data/tuberculosis/TB_Chest_Radiography_Database/')\n",
    "\n",
    "tb_imgs = list((tb_dir / 'Tuberculosis').glob('*.png'))\n",
    "normal_imgs = list((tb_dir / 'Normal').glob('*.png'))\n",
    "\n",
    "print(f\"Found {len(tb_imgs)} TB images\")\n",
    "print(f\"Found {len(normal_imgs)} Normal images\")\n",
    "\n",
    "num_sample_per_class = 700\n",
    "np.random.seed(42)\n",
    "\n",
    "# Sample images\n",
    "tb_imgs_sampled = np.random.choice(tb_imgs, size=num_sample_per_class, replace=False)\n",
    "normal_imgs_sampled = np.random.choice(normal_imgs, size=num_sample_per_class, replace=False)\n",
    "\n",
    "print(f\"\\nSampled {len(tb_imgs_sampled)} TB images\")\n",
    "print(f\"Sampled {len(normal_imgs_sampled)} Normal images\")\n",
    "\n",
    "# Create DataFrame\n",
    "data = []\n",
    "for img_path in tb_imgs_sampled:\n",
    "    data.append({\n",
    "        'imgpath': str(img_path),\n",
    "        'TB': 1,\n",
    "        'Normal': 0,\n",
    "    })\n",
    "\n",
    "for img_path in normal_imgs_sampled:\n",
    "    data.append({\n",
    "        'imgpath': str(img_path),\n",
    "        'TB': 0,\n",
    "        'Normal': 1,\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save sampled csv\n",
    "output_path = Path('local_data/tb-test-meta.csv')\n",
    "output_path.parent.mkdir(exist_ok=True)\n",
    "df.to_csv(output_path)\n",
    "print(f\"\\nSaved metadata to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10fbe41a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load data from ./local_data/tb-test-meta.csv\n",
      "Dataset size: 1400\n",
      "Class names: ['TB', 'Normal']\n",
      "\n",
      "Sample image shape: torch.Size([1, 1, 224, 224])\n",
      "Sample label:\n",
      "  TB Normal\n",
      "0  1      0\n"
     ]
    }
   ],
   "source": [
    "class_names = ['TB', 'Normal']\n",
    "\n",
    "dataset = ZeroShotImageDataset(\n",
    "    datalist=['tb-test'],  # will load from local_data/tb-test-meta.csv\n",
    "    class_names=class_names\n",
    ")\n",
    "\n",
    "print(f\"Dataset size: {len(dataset)}\")\n",
    "print(f\"Class names: {class_names}\")\n",
    "\n",
    "# Check a sample\n",
    "img, label = dataset[0]\n",
    "print(f\"\\nSample image shape: {img.shape}\")\n",
    "print(f\"Sample label:\")\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dd618c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample 10 num of prompts for Tuberculosis from total 480\n",
      "\n",
      "Generated prompts for classes: ['Tuberculosis']\n",
      "Number of prompts per class: [10]\n",
      "\n",
      "Available TB prompts:\n",
      "  Tuberculosis: 10 prompts\n",
      "    Examples: ['reticulonodular lung lesion with volume loss in the upper lung zones', 'reticulonodular lung opacity with volume loss in the upper lung zones']\n"
     ]
    }
   ],
   "source": [
    "# Generate TB class prompts\n",
    "tb_prompts = generate_tb_class_prompts(n=10)\n",
    "print(f\"\\nGenerated prompts for classes: {list(tb_prompts.keys())}\")\n",
    "print(f\"Number of prompts per class: {[len(v) for v in tb_prompts.values()]}\")\n",
    "\n",
    "print(f\"\\nAvailable TB prompts:\")\n",
    "for cls, prompts_list in tb_prompts.items():\n",
    "    print(f\"  {cls}: {len(prompts_list)} prompts\")\n",
    "    print(f\"    Examples: {prompts_list[:2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b05124c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_prompts['Tuberculosis'] = [f'this x-ray image describes {prompt}' for prompt in tb_prompts['Tuberculosis']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "879e3c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class prompts prepared:\n",
      "  TB: 10 prompts\n",
      "  Normal: 10 prompts\n"
     ]
    }
   ],
   "source": [
    "cls_prompts_dict = {\n",
    "    'TB': tb_prompts['Tuberculosis'],\n",
    "    'Normal': [\n",
    "        'no findings',\n",
    "        'no evidence of pneumonia',\n",
    "        'normal chest x-ray',\n",
    "        'clear lungs',\n",
    "        'no acute disease',\n",
    "        'no radiographic abnormality',\n",
    "        'healthy chest radiograph',\n",
    "        'unremarkable chest x-ray',\n",
    "        'no pathological findings',\n",
    "        'normal cardiomediastinal silhouette',\n",
    "        # 'no infiltrates',\n",
    "        # 'normal pulmonary vasculature'\n",
    "    ]\n",
    "}\n",
    "\n",
    "cls_prompts_dict['Normal'] = [f'this x-ray image describes {prompt}' for prompt in cls_prompts_dict['Normal']]\n",
    "\n",
    "print(f\"Class prompts prepared:\")\n",
    "for cls, prompts in cls_prompts_dict.items():\n",
    "    print(f\"  {cls}: {len(prompts)} prompts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b06f501b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dongyoun/miniconda3/envs/medclip_eval/lib/python3.10/site-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoader created with batch_size=32\n",
      "Number of batches: 44\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\n",
      "Sample batch keys: dict_keys(['pixel_values', 'prompt_inputs', 'labels'])\n",
      "Pixel values shape: torch.Size([32, 3, 224, 224])\n",
      "Labels shape: torch.Size([32])\n",
      "Prompt inputs keys: dict_keys(['TB', 'Normal'])\n"
     ]
    }
   ],
   "source": [
    "# Create collator with prompts\n",
    "collator = ZeroShotImageCollator(\n",
    "    mode='binary',  # binary classification: TB vs Normal\n",
    "    cls_prompts=cls_prompts_dict\n",
    ")\n",
    "\n",
    "# Create DataLoader\n",
    "batch_size = 32\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    collate_fn=collator,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "print(f\"DataLoader created with batch_size={batch_size}\")\n",
    "print(f\"Number of batches: {len(dataloader)}\")\n",
    "\n",
    "# Test the dataloader\n",
    "sample_batch = next(iter(dataloader))\n",
    "print(f\"\\nSample batch keys: {sample_batch.keys()}\")\n",
    "print(f\"Pixel values shape: {sample_batch['pixel_values'].shape}\")\n",
    "print(f\"Labels shape: {sample_batch['labels'].shape}\")\n",
    "print(f\"Prompt inputs keys: {sample_batch['prompt_inputs'].keys()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "13456fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dongyoun/miniconda3/envs/medclip_eval/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/dongyoun/miniconda3/envs/medclip_eval/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/Users/dongyoun/miniconda3/envs/medclip_eval/lib/python3.10/site-packages/transformers/modeling_utils.py:399: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
      "Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/Users/dongyoun/projects/dongYoun2/MedCLIP_eval/medclip/modeling_medclip.py:213: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(os.path.join(input_dir, constants.WEIGHTS_NAME), map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model moved to mps\n",
      "load model weight from: pretrained/medclip-resnet\n",
      "Model and classifier ready for evaluation\n"
     ]
    }
   ],
   "source": [
    "processor = MedCLIPProcessor()\n",
    "model = MedCLIPModel.from_pretrained(vision_model='resnet', device='mps')\n",
    "clf = PromptClassifier(model, ensemble=True)\n",
    "clf.to('mps')\n",
    "clf.eval()\n",
    "\n",
    "print(\"Model and classifier ready for evaluation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ccf4017f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluator created, starting evaluation...\n"
     ]
    }
   ],
   "source": [
    "evaluator = Evaluator(\n",
    "    medclip_clf=clf,\n",
    "    eval_dataloader=dataloader,\n",
    "    mode='binary'\n",
    ")\n",
    "\n",
    "print(\"Evaluator created, starting evaluation...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9802769a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation:   0%|          | 0/44 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 100%|██████████| 44/44 [00:21<00:00,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "EVALUATION RESULTS\n",
      "==================================================\n",
      "acc                 : 0.5493\n",
      "precision           : 0.6414\n",
      "recall              : 0.5493\n",
      "f1-score            : 0.4616\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Run evaluation\n",
    "results = evaluator.evaluate()\n",
    "\n",
    "# Display results\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"EVALUATION RESULTS\")\n",
    "print(\"=\"*50)\n",
    "for metric, value in results.items():\n",
    "    if metric not in ['pred', 'labels']:\n",
    "        print(f\"{metric:20s}: {value:.4f}\")\n",
    "print(\"=\"*50)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medclip_eval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
